{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpxoYrfWNbDI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpvdtyO4PN_s"
   },
   "outputs": [],
   "source": [
    "#Building vocabulary and converting each statement into vector\n",
    "\n",
    "def create_unique(text_arr):\n",
    "  dictt = {}\n",
    "  count = -1\n",
    "  x = np.array(text_arr)\n",
    "  \n",
    "  text = np.unique(x)\n",
    "  #print(text)\n",
    "  for item in text:\n",
    "    data = (item.lower().strip().split(\" \"))\n",
    "    for item1 in data:\n",
    "      if item1 not in dictt:\n",
    "        count = count +1\n",
    "        dictt[item1] = count\n",
    "  \n",
    "  print(dictt)  \n",
    "  return dictt\n",
    "\n",
    "\n",
    "def vectorize(text_arr, dictt):\n",
    "  vectors = []\n",
    "  #print(text_arr)\n",
    "  for sentence in text_arr:\n",
    "    vector = [0] * len(dictt)\n",
    "    words = (sentence.lower().strip().split(\" \"))\n",
    "    for word in words:\n",
    "      index = dictt[word]\n",
    "      vector[index] += 1\n",
    "    \n",
    "    vectors.append(vector)\n",
    "    #print(sentence)\n",
    "  print(array(vectors))\n",
    "  return vectors\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "# text = [\"Hello, my name is XYZ, and your name is ABC. Nice to meet you.\", \"Lol, what is your name?\"]\n",
    "# dictt = create_unique(text)\n",
    "# vector = vectorize(text, dictt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1s8Nk063drJe"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  \n",
    "  #initializing object\n",
    "  def __init__(self, lr, num_iter, threshold = 0.5):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.threshold = threshold\n",
    "  \n",
    "  #adding X0 to X matrix, feature matrix\n",
    "  def __add_intercept(self, X):\n",
    "    ones = np.ones(X.shape[0],1)\n",
    "    return np.concatenate((ones,X), axis=1)\n",
    "  \n",
    "  #defining sigmoid funcion\n",
    "  def _sigmoid(self,X):\n",
    "    return (1/(1+exp(-X)))\n",
    "  \n",
    "  #defining loss function\n",
    "  def __loss(self, h, y):\n",
    "    first_term = -y*np.log(h)\n",
    "    second_term = -(1-y)*np.log(1-h)\n",
    "    return (first_term + second_term).mean()\n",
    "  \n",
    "  #training and deriving the theta vector\n",
    "  def _train(self,X,y):\n",
    "    X = self.__add_intercept(X)\n",
    "    \n",
    "    #Initializing theta vector as zeroes\n",
    "    self.theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    #making model equation and doing gradient descent\n",
    "    for i in range(self.num_iter):\n",
    "      z = np.dot(X,self.theta)\n",
    "      h = self._sigmoid(z)\n",
    "      \n",
    "      gradient = np.dot(X.T,(h-y))/y.size()\n",
    "      self.theta -= self.lr*gradient\n",
    "      \n",
    "      z = np.dot(X,self.theta)\n",
    "      h = self._sigmoid(z)\n",
    "      loss = self.__loss(h,y)\n",
    "      \n",
    "    file = open(\"spam_model.pickle\", \"wb\")\n",
    "    pickle.dump(seld.theta, file)\n",
    "    file.close()\n",
    "    \n",
    "    return True\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sample_logistic",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
